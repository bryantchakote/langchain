{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive splitter: ['abcdefghijklmnopqrstuvwxyz', 'wxyzABCDEFGHIJKLMNOPQRSTUV', 'STUVWXYZ']\n",
      "Character splitter: ['abcdefghijklmnopqrstuvwxyz', 'wxyzABCDEFGHIJKLMNOPQRSTUV', 'STUVWXYZ']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "chunk_size = 26\n",
    "chunk_overlap = 4\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "c_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap, separator=\"\")  # separator defaults to \"\\n\"\n",
    "# The character splitter splits depending on a separator as the Python's native str.split method\n",
    "# The chunks can be longer than chunk_size if the separator is not found, and a warning is thrown\n",
    "\n",
    "text = string.ascii_letters\n",
    "\n",
    "print(\"Recursive splitter:\", r_splitter.split_text(text))\n",
    "print(\"Character splitter:\", c_splitter.split_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentences. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\"\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When writing documents, writers will use document structure to group '\n",
      " \"content. This can convey to the reader, which idea's are related. For \"\n",
      " 'example, closely related ideas are in sentences. Similar ideas are in '\n",
      " 'paragraphs. Paragraphs form a document.',\n",
      " 'Paragraphs are often delimited with a carriage return or two carriage '\n",
      " 'returns. Carriage returns are the \"backslash n\" you see embedded in this '\n",
      " 'string. Sentences have a period at the end, but also, have a space.and words '\n",
      " 'are separated by space.']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    # First try to split by \"\\n\\n\", then \"\\n\", etc. -> better split\n",
    "    # The regex trick is to have the period at the end of the right sentence\n",
    "    separators=[\"\\n\\n\", \"\\n\", r\"(?<=\\. )\", \" \", \"\"],\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "pprint(r_splitter.split_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pages: 22\n",
      "docs: 78\n"
     ]
    }
   ],
   "source": [
    "# Try with a longer document\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"docs/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", r\"(?<=\\. )\", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    # Token count can be used as length function, or\n",
    "    # directly the langchain.text_splitter TokenTextSplitter \n",
    "    length_function=len,\n",
    ")\n",
    "docs = splitter.split_documents(pages)\n",
    "\n",
    "print(\"pages:\", len(pages))\n",
    "print(\"docs:\", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Title\n",
      "\n",
      " ## Chapter 1\n",
      "\n",
      " Hi this is Jim\n",
      "\n",
      " Hi this is Joe\n",
      "\n",
      " ### Section \n",
      "\n",
      " Hi this is Lance \n",
      "\n",
      " \n",
      "## Chapter 2\n",
      "\n",
      " Hi this is Molly\n"
     ]
    }
   ],
   "source": [
    "# Context-aware splitting (useful for Markdown docs)\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "md_doc = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\"\n",
    "\n",
    "print(md_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'}, page_content='Hi this is Jim  \\nHi this is Joe')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "md_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "md_splits = md_splitter.split_text(md_doc)\n",
    "\n",
    "md_splits[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
