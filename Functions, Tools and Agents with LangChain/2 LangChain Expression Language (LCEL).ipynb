{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Expression Language (LCEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why did the banana go to the doctor? \\n\\nBecause it wasn't peeling well! üçå\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "chain.invoke({\"topic\": \"bananas\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complex (add retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tchak\\anaconda3\\envs\\langchain\\Lib\\site-packages\\pydantic\\_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\n",
    "        \"Harrison worked at Kensho\",\n",
    "        \"Bears like to eat honey\",\n",
    "    ],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Harrison worked at Kensho'),\n",
       " Document(metadata={}, page_content='Bears like to eat honey')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Where did Harrison work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Bears like to eat honey'),\n",
       " Document(metadata={}, page_content='Harrison worked at Kensho')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What do bears like to eat?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Where did Harrison work?', 'context': [Document(metadata={}, page_content='Harrison worked at Kensho'), Document(metadata={}, page_content='Bears like to eat honey')]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableMap\n",
    "\n",
    "inputs = RunnableMap({\n",
    "    \"question\": lambda x: x[\"question\"],\n",
    "    \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "})\n",
    "chain = inputs | prompt | model | output_parser\n",
    "\n",
    "print(inputs.invoke({\"question\": \"Where did Harrison work?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harrison worked at Kensho.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"question\": \"Where did Harrison work?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bind (OpenAI functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"weather_search\",\n",
    "        \"description\": \"Search for weather given an airport code\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"airport_code\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The airport code to get the weather for\"\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"airport_code\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"sports_search\",\n",
    "        \"description\": \"Search for news of recent sport events\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"team_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The sports team to search for\"\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"team_name\"],\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "model = ChatOpenAI().bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'weather_search'}, 'refusal': None}\n",
      "{'function_call': {'arguments': '{\"team_name\":\"Patriots\"}', 'name': 'sports_search'}, 'refusal': None}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | model\n",
    "print(chain.invoke({\"input\": \"What's the weather is SF?\"}).additional_kwargs)\n",
    "print(chain.invoke({\"input\": \"How did the Patriots do yesterday?\"}).additional_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fallbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.language_models.fake_chat_models import FakeChatModel\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='fake response' additional_kwargs={} response_metadata={} id='run-20b758e9-6874-40b5-890f-b772940ac5f5-0'\n"
     ]
    }
   ],
   "source": [
    "simple_model = FakeChatModel()\n",
    "simple_chain = simple_model | StrOutputParser() |json.loads\n",
    "\n",
    "challenge = \"Write three poems in a json blob, where each poem is a json blob of a title, author, and first line\"\n",
    "\n",
    "print(simple_model.invoke(challenge))\n",
    "\n",
    "# simple_chain.invoke(challenge) # fails because the output \"fake response\" can't be converted to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poem1': {'title': 'The Rose',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'first_line': 'A rose by any other name would smell as sweet'},\n",
       " 'poem2': {'title': 'The Road Not Taken',\n",
       "  'author': 'Robert Frost',\n",
       "  'first_line': 'Two roads diverged in a yellow wood'},\n",
       " 'poem3': {'title': 'Hope is the Thing with Feathers',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'first_line': 'Hope is the thing with feathers that perches in the soul'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatOpenAI(temperature=0)\n",
    "chain = model | StrOutputParser() | json.loads\n",
    "\n",
    "chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poem1': {'title': 'The Rose',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'A rose by any other name would smell as sweet'},\n",
       " 'poem2': {'title': 'The Road Not Taken',\n",
       "  'author': 'Robert Frost',\n",
       "  'firstLine': 'Two roads diverged in a yellow wood'},\n",
       " 'poem3': {'title': 'Hope is the Thing with Feathers',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'Hope is the thing with feathers that perches in the soul'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain = simple_chain.with_fallbacks([chain])\n",
    "final_chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface: invoke, batch, stream, async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the gorilla go to the doctor? Because he was feeling a little \"ape\"-y!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"gorillas\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Why did the firefighter wear red suspenders? To keep his pants up while he's putting out fires!\",\n",
       " 'Why did the horse sit at the computer? He wanted to be a \"neigh\" sayer!']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([\n",
    "    {\"topic\": \"fire\"},\n",
    "    {\"topic\": \"horse\"},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why\n",
      " did\n",
      " the\n",
      " glass\n",
      " go\n",
      " to\n",
      " therapy\n",
      "?\n",
      " Because\n",
      " it\n",
      " had\n",
      " a\n",
      " lot\n",
      " of\n",
      " transparency\n",
      " issues\n",
      "!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in chain.stream({\"topic\": \"glass\"}):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why did the bear break up with his girlfriend?\\nBecause he couldn't bear the relationship any longer!\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await chain.ainvoke({\"topic\": \"bears\"})\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
